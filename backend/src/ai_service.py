"""
AI Service for Essay Correction - Multi-Provider Support
Supports: Groq, Gemini, HuggingFace, Together AI
"""

import json
import logging
import os
import asyncio
import re
from typing import Optional

logger = logging.getLogger(__name__)

def extract_json_robust(text: str) -> dict:
    """
    Extrai JSON de uma string de forma robusta, buscando o primeiro '{' e o √∫ltimo '}'.
    Remove blocos de c√≥digo markdown se houver.
    """
    text = text.strip()
    
    # Remove blocos de c√≥digo markdown ```json ... ```
    if "```" in text:
        # Tenta extrair conte√∫do dentro de ```json ou apenas ```
        match = re.search(r"```(?:json)?(.*?)```", text, re.DOTALL)
        if match:
            text = match.group(1).strip()
            
    # Encontra o primeiro '{' e o √∫ltimo '}'
    start = text.find('{')
    end = text.rfind('}')
    
    if start != -1 and end != -1:
        json_str = text[start:end+1]
        try:
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            logger.error(f"Erro ao decodificar JSON extra√≠do: {e}")
            # Tenta limpar v√≠rgulas finais (trailing commas) que o JSON padr√£o n√£o aceita
            try:
                json_str_clean = re.sub(r",\s*}", "}", json_str)
                json_str_clean = re.sub(r",\s*]", "]", json_str_clean)
                return json.loads(json_str_clean)
            except:
                pass
            raise ValueError(f"Falha ao extrair JSON v√°lido. Texto: {text[:100]}...")
    
    raise ValueError("Nenhum objeto JSON encontrado na resposta da IA")

async def retry_with_backoff(func, *args, max_retries=3, initial_delay=1, **kwargs):
    """
    Executa uma fun√ß√£o async com retry e backoff exponencial.
    """
    delay = initial_delay
    last_exception = None
    
    for attempt in range(max_retries):
        try:
            return await func(*args, **kwargs)
        except Exception as e:
            last_exception = e
            logger.warning(f"Tentativa {attempt+1}/{max_retries} falhou: {str(e)}. Retentando em {delay}s...")
            if attempt < max_retries - 1:
                await asyncio.sleep(delay)
                delay *= 2  # Backoff exponencial
    
    logger.error(f"Todas as {max_retries} tentativas falharam.")
    raise last_exception

# Provider configurations
AI_PROVIDERS = {
    'groq': {
        'name': 'Groq',
        'env_var': 'GROQ_API_KEY',
        'default_model': 'llama-3.1-70b-versatile'
    },
    'gemini': {
        'name': 'Google Gemini',
        'env_var': 'GEMINI_API_KEY',
        'default_model': 'gemini-2.0-flash'
    },
    'huggingface': {
        'name': 'HuggingFace',
        'env_var': 'HF_TOKEN',
        'default_model': 'mistralai/Mixtral-8x7B-Instruct-v0.1'
    },
    'together':  {
        'name': 'Together AI',
        'env_var': 'TOGETHER_API_KEY',
        'default_model': 'meta-llama/Llama-3-70b-chat-hf'
    }
}

# Prompt aprimorado com calibra√ß√£o e crit√©rios objetivos
CORRECTION_PROMPT = """Voc√™ √© um corretor OFICIAL do ENEM. Analise esta reda√ß√£o seguindo RIGOROSAMENTE os crit√©rios oficiais.

**üìä ESCALA DE CALIBRA√á√ÉO (distribui√ß√£o estat√≠stica t√≠pica):**
- 200 pontos: <5% das reda√ß√µes (texto excepcional, refer√™ncia nacional)
- 160 pontos: 15-20% (texto muito bom, acima da m√©dia)
- 120 pontos: 40-50% (texto adequado, dentro do esperado) ‚Üê FAIXA MAIS COMUM
- 80 pontos: 20-25% (texto mediano, abaixo do esperado)
- 40 pontos: 5-10% (texto insuficiente, problemas s√©rios)
- 0 pontos: <2% (texto inadequado, problemas grav√≠ssimos)

**üìù CHECKLIST OBRIGAT√ìRIO ANTES DE PONTUAR:**

Para CADA compet√™ncia, voc√™ DEVE verificar objetivamente:

**C1 - Norma Culta:**
‚ñ° Quantos erros de ortografia? ___
‚ñ° Quantos erros de pontua√ß√£o? ___
‚ñ° Quantos erros de concord√¢ncia? ___
‚ñ° Quantos erros de reg√™ncia? ___
‚Üí 0-2 erros = 160-200 | 3-5 erros = 120-160 | 6-10 erros = 80-120 | 11+ erros = 40-80

**C2 - Compreens√£o do Tema:**
‚ñ° O tema foi compreendido corretamente? (Sim/N√£o)
‚ñ° H√° tangenciamento? (N√£o/Leve/Moderado/Grave)
‚ñ° Desenvolvimento: (Superficial/Adequado/Aprofundado)
‚Üí Completo = 160-200 | Adequado = 120-160 | Tangente leve = 80-120

**C3 - Argumenta√ß√£o:**
‚ñ° Quantos argumentos bem desenvolvidos? ___
‚ñ° H√° repert√≥rio sociocultural? (N√£o/Superficial/Legitimado)
‚ñ° Argumenta√ß√£o √© autoral ou gen√©rica?
‚Üí 3+ argumentos + repert√≥rio legitimado = 160-200 | 2 argumentos adequados = 120-160 | 1-2 argumentos fracos = 80-120

**C4 - Coes√£o:**
‚ñ° Quantos conectivos ADEQUADOS usados? ___
‚ñ° H√° problemas de coer√™ncia? (N√£o/Leve/Grave)
‚ñ° Progress√£o textual: (Excelente/Boa/Adequada/Problem√°tica)
‚Üí 8+ conectivos variados = 160-200 | 5-7 conectivos = 120-160 | 3-4 conectivos = 80-120

**C5 - Proposta de Interven√ß√£o:**
‚ñ° A√á√ÉO detalhada? (Sim/N√£o)
‚ñ° AGENTE claro? (Sim/N√£o)
‚ñ° MODO/MEIO especificado? (Sim/N√£o)
‚ñ° EFEITO/FINALIDADE clara? (Sim/N√£o)
‚ñ° DETALHAMENTO suficiente? (Sim/N√£o)
‚Üí 5 elementos = 200 | 4 elementos = 160 | 3 elementos = 120 | 2 elementos = 80

**üéì EXEMPLOS DE CALIBRA√á√ÉO (few-shot learning):**

EXEMPLO 1 - Reda√ß√£o nota 840 (168 m√©dia):
"A tecnologia como ponte para a inclus√£o digital no Brasil"
- C1: 160pts (2 desvios leves de pontua√ß√£o)
- C2: 180pts (tema muito bem desenvolvido, perspectiva cr√≠tica)
- C3: 160pts (2 argumentos s√≥lidos, repert√≥rio de soci√≥logos)
- C4: 180pts (progress√£o clara, 9 conectivos variados)
- C5: 160pts (4 dos 5 elementos: a√ß√£o+agente+modo+efeito)
Caracter√≠sticas: linguagem fluida, repert√≥rio legitimado, estrutura clara, proposta vi√°vel.

EXEMPLO 2 - Reda√ß√£o nota 600 (120 m√©dia):
"Os desafios da mobilidade urbana nas grandes cidades"
- C1: 120pts (5 desvios: concord√¢ncia e acentua√ß√£o)
- C2: 120pts (tema adequadamente desenvolvido, sem aprofundamento)
- C3: 120pts (2 argumentos previs√≠veis, repert√≥rio superficial)
- C4: 120pts (5 conectivos, alguns repetidos)
- C5: 120pts (3 elementos: a√ß√£o+agente+modo)
Caracter√≠sticas: linguagem simples, argumentos gen√©ricos, estrutura b√°sica, proposta incompleta.

EXEMPLO 3 - Reda√ß√£o nota 400 (80 m√©dia):
"A importancia da educa√ßao finanseira"
- C1: 80pts (10 erros: ortografia, acentua√ß√£o, concord√¢ncia)
- C2: 80pts (tangenciamento moderado do tema)
- C3: 80pts (1 argumento desenvolvido, sem repert√≥rio)
- C4: 80pts (3 conectivos b√°sicos, repeti√ß√£o de ideias)
- C5: 80pts (2 elementos vagos: a√ß√£o+agente gen√©ricos)
Caracter√≠sticas: erros frequentes, pouco desenvolvimento, estrutura fr√°gil, proposta vaga.

**‚ö†Ô∏è DIRETRIZES CR√çTICAS:**
1. Seja OBJETIVO: conte erros, conectivos, argumentos
2. Seja CONSISTENTE: use a escala de calibra√ß√£o
3. Seja JUSTO: notas 120-160 s√£o NORMAIS, n√£o tenha medo de us√°-las
4. Seja CRITERIOSO: nota 200 exige perfei√ß√£o quase absoluta
5. EVITE: dar sempre a mesma nota ou notas muito extremas

Retorne APENAS JSON v√°lido:

```json
{{
  "competence_1_score": 120,
  "competence_1_feedback": "üìä Erros contados: X ortografia, Y pontua√ß√£o, Z concord√¢ncia.\\n\\n‚úÖ Pontos Fortes: [listar espec√≠ficos]\\n\\n‚ö†Ô∏è O que melhorar: [listar espec√≠ficos]",
  "competence_2_score": 160,
  "competence_2_feedback": "üìä Avalia√ß√£o: [tangenciamento/desenvolvimento].\\n\\n‚úÖ Pontos Fortes: [espec√≠ficos]\\n\\n‚ö†Ô∏è O que melhorar: [espec√≠ficos]",
  "competence_3_score": 120,
  "competence_3_feedback": "üìä Argumentos: X desenvolvidos, repert√≥rio [tipo].\\n\\n‚úÖ Pontos Fortes: [espec√≠ficos]\\n\\n‚ö†Ô∏è O que melhorar: [espec√≠ficos]",
  "competence_4_score": 80,
  "competence_4_feedback": "üìä Conectivos: X adequados identificados.\\n\\n‚úÖ Pontos Fortes: [espec√≠ficos]\\n\\n‚ö†Ô∏è O que melhorar: [espec√≠ficos]",
  "competence_5_score": 120,
  "competence_5_feedback": "üìä Elementos presentes: X de 5 (a√ß√£o, agente, modo, efeito, detalhamento).\\n\\n‚úÖ Pontos Fortes: [espec√≠ficos]\\n\\n‚ö†Ô∏è O que melhorar: [espec√≠ficos]",
  "total_score": 600,
  "strengths": ["For√ßa espec√≠fica 1", "For√ßa espec√≠fica 2"],
  "improvements": ["Melhoria espec√≠fica 1", "Melhoria espec√≠fica 2"],
  "general_comments": "Coment√°rio geral construtivo baseado na an√°lise objetiva."
}}
```

**REDA√á√ÉO A AVALIAR:**

T√≠tulo: {title}
Tema: {theme}

{content}
"""


def get_active_provider() -> tuple[str, Optional[str]]:
    """
    Get active AI provider from database + environment.
    Returns: (provider_name, api_key)
    """
    from .database import SessionLocal, init_db_engine
    from .models import Settings
    
    print("\nüîç ==== CHECKING ACTIVE AI PROVIDER ====")
    
    # Ensure SessionLocal is initialized
    if SessionLocal is None:
        print("‚ö†Ô∏è SessionLocal not initialized, initializing now...")
        init_db_engine()
        # Re-import after initialization
        from .database import SessionLocal as SL
    else:
        SL = SessionLocal
    
    # Get active provider from database
    db = SL()
    try:
        settings = db.query(Settings).first()
        if settings:
            active_provider = settings.active_ai_provider
            print(f"üìä Database says active provider: {active_provider}")
        else:
            active_provider = "groq"  # Default fallback
            print(f"‚ö†Ô∏è No settings in DB, using default: {active_provider}")
    finally:
        db.close()
    
    # Get API key from environment for the active provider
    if active_provider == "groq":
        groq_key = os.getenv('GROQ_API_KEY')
        print(f"GROQ_API_KEY present: {bool(groq_key)}")
        if groq_key:
            print(f"‚úÖ Using GROQ provider with key: {groq_key[:20]}...")
            logger.info("Using Groq AI provider")
            return ('groq', groq_key)
        else:
            print("‚ùå Groq selected but no API key in .env!")
            logger.error("Groq selected but GROQ_API_KEY not configured in .env")
            return ('groq', None)
    
    elif active_provider == "gemini":
        gemini_key = os.getenv('GEMINI_API_KEY')
        print(f"GEMINI_API_KEY present: {bool(gemini_key)}")
        if gemini_key:
            print(f"‚úÖ Using GEMINI provider")
            logger.info("Using Gemini AI provider")
            return ('gemini', gemini_key)
        else:
            print("‚ùå Gemini selected but no API key in .env!")
            logger.error("Gemini selected but GEMINI_API_KEY not configured in .env")
            return ('gemini', None)
    
    elif active_provider == "huggingface":
        hf_token = os.getenv('HF_TOKEN')
        print(f"HF_TOKEN present: {bool(hf_token)}")
        if hf_token:
            print(f"‚úÖ Using HuggingFace provider")
            return ('huggingface', hf_token)
        else:
            print("‚ùå HuggingFace selected but no API key in .env!")
            return ('huggingface', None)
    
    elif active_provider == "together":
        together_key = os.getenv('TOGETHER_API_KEY')
        print(f"TOGETHER_API_KEY present: {bool(together_key)}")
        if together_key:
            print(f"‚úÖ Using Together AI provider")
            return ('together', together_key)
        else:
            print("‚ùå Together selected but no API key in .env!")
            return ('together', None)
    
    # Unknown provider
    print(f"‚ùå Unknown provider in database: {active_provider}")
    logger.error(f"Unknown provider configured: {active_provider}")
    return (active_provider, None)


async def correct_with_groq(title: str, theme: str, content: str, api_key: str) -> dict:
    """Correct essay using Groq API"""
    try:
        from groq import Groq
        
        client = Groq(api_key=api_key)
        
        prompt = CORRECTION_PROMPT.format(title=title, theme=theme or "", content=content)
        
        print(f"üì§ Sending to Groq: {title}")
        logger.info(f"Sending to Groq: {title}")
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,  # Low temperature for consistent scoring
            max_tokens=2048
        )
        
        text = response.choices[0].message.content.strip()
        
        data = extract_json_robust(text)
        data['strengths'] = json.dumps(data.get('strengths', []), ensure_ascii=False)
        data['improvements'] = json.dumps(data.get('improvements', []), ensure_ascii=False)
        
        print(f"‚úÖ Groq correction completed. Score: {data.get('total_score')}")
        logger.info(f"Groq correction completed. Score: {data.get('total_score')}")
        return data
        
    except Exception as e:
        print(f"‚ùå Groq error: {e}")
        logger.error(f"Groq error: {e}")
        raise


async def correct_with_gemini(title: str, theme: str, content: str, api_key: str) -> dict:
    """Correct essay using Gemini API"""
    try:
        import google.generativeai as genai
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.0-flash')
        
        prompt = CORRECTION_PROMPT.format(title=title, theme=theme or "", content=content)
        
        logger.info(f"Sending to Gemini: {title}")
        
        response = model.generate_content(
            prompt,
            generation_config=genai.GenerationConfig(temperature=0.1, max_output_tokens=2048),
            safety_settings=[
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]
        )
        
        # Check for safety block
        if hasattr(response, 'candidates') and len(response.candidates) > 0:
            if response.candidates[0].finish_reason == 2:
                logger.warning("Gemini blocked by safety")
                raise Exception("Blocked by safety filters")
        
        text = response.text.strip()
        
        data = extract_json_robust(text)
        data['strengths'] = json.dumps(data.get('strengths', []), ensure_ascii=False)
        data['improvements'] = json.dumps(data.get('improvements', []), ensure_ascii=False)
        
        logger.info(f"Gemini correction completed. Score: {data.get('total_score')}")
        return data
        
    except Exception as e:
        logger.error(f"Gemini error: {e}")
        raise


async def correct_essay_with_gemini(title: str, theme: str, content: str, exam_type: str = 'enem') -> dict:
    """
    Main correction function - routes to active provider
    Maintains backward compatibility with existing code
    """
    provider, api_key = get_active_provider()
    
    if not api_key:
        raise Exception(f"API key not configured for provider: {provider}")
    
    print(f"ü§ñ Using AI provider: {AI_PROVIDERS[provider]['name']}")
    logger.info(f"Using AI provider: {AI_PROVIDERS[provider]['name']}")
    
    # Define wrapper functions for retry
    async def run_groq():
        # Import prompt_builder to use specific prompts
        from .prompt_builder import create_correction_prompt
        prompt = create_correction_prompt(exam_type, title, theme, content)
        return await correct_with_groq_custom_prompt(
            title, theme, content, api_key, prompt, model="llama-3.1-8b-instant"
        )
        
    async def run_gemini():
        # Import prompt_builder to use specific prompts
        from .prompt_builder import create_correction_prompt
        prompt = create_correction_prompt(exam_type, title, theme, content)
        return await correct_with_gemini_custom_prompt(title, theme, content, api_key, prompt)

    try:
        if provider == 'groq':
            return await retry_with_backoff(run_groq, max_retries=3)
        elif provider == 'gemini':
           return await retry_with_backoff(run_gemini, max_retries=3)
        elif provider == 'huggingface':
            # TODO: Implement HuggingFace
            raise Exception("HuggingFace provider not implemented yet")
        elif provider == 'together':
            # TODO: Implement Together AI
            raise Exception("Together AI provider not implemented yet")
        else:
            raise Exception(f"Unknown provider: {provider}")
            
    except Exception as e:
        # Log error and re-raise (no silent fallback)
        print(f"‚ùå AI correction failed: {e}")
        logger.error(f"AI correction failed: {e}")
        raise Exception(f"Falha na corre√ß√£o com {provider}: {str(e)}. Verifique se a API key est√° configurada corretamente.")


async def generate_theme_with_gemini(category: str) -> str:
    """Generate theme using active provider"""
    provider, api_key = get_active_provider()
    
    if provider == 'groq' and api_key:
        try:
            from groq import Groq
            client = Groq(api_key=api_key)
            response = client.chat.completions.create(
                model="llama-3.1-70b-versatile",
                messages=[{"role": "user", "content": f"Gere um tema dissertativo sobre {category}. M√°ximo 15 palavras. Responda APENAS o tema, sem aspas."}],
                temperature=0.8,
                max_tokens=100
            )
            return response.choices[0].message.content.strip().replace('"', '').replace("'", "")
        except:
            pass
    
    # Fallback themes
    return {
        'geral': 'A import√¢ncia da educa√ß√£o no Brasil contempor√¢neo',
        'educacao': 'Desafios da forma√ß√£o de professores no Brasil',
        'tecnologia': 'O impacto da intelig√™ncia artificial na sociedade',
        'meio_ambiente': 'Sustentabilidade e desenvolvimento econ√¥mico',
        'sociedade': 'A import√¢ncia do di√°logo na resolu√ß√£o de conflitos',
        'saude': 'Desafios do sistema de sa√∫de p√∫blica no Brasil'
    }.get(category, 'A educa√ß√£o como instrumento de transforma√ß√£o social')

# ===== PREMIUM CORRECTION FUNCTIONS =====

# Refinement prompt
REFINEMENT_PROMPT = """Voc√™ √© um ESPECIALISTA PREMIUM em reda√ß√£o ENEM nota 1000.

Recebeu esta corre√ß√£o inicial:

**NOTAS:**
Compet√™ncia 1: {comp1_score}/200
Compet√™ncia 2: {comp2_score}/200
Compet√™ncia 3: {comp3_score}/200
Compet√™ncia 4: {comp4_score}/200
Compet√™ncia 5: {comp5_score}/200

Para CADA compet√™ncia, adicione insights premium com:
1. Exemplos pr√°ticos do texto
2. Como reda√ß√µes nota 1000 fazem
3. Sugest√£o estrat√©gica avan√ßada

Retorne JSON:
{{
  "competence_1_premium_insights": "...",
  "competence_2_premium_insights": "...",
  "competence_3_premium_insights": "...",
  "competence_4_premium_insights": "...",
  "competence_5_premium_insights": "...",
  "general_premium_insights": "Vis√£o estrat√©gica geral"
}}

Texto:
{content}
"""


async def refine_with_gemini(title: str, theme: str, content: str, groq_result: dict, api_key: str) -> dict:
    """Refine Groq correction with Gemini premium insights"""
    try:
        import google.generativeai as genai
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.0-flash')
        
        # Prepare prompt
        prompt = REFINEMENT_PROMPT.format(
            comp1_score=groq_result.get('competence_1_score', 0),
            comp2_score=groq_result.get('competence_2_score', 0),
            comp3_score=groq_result.get('competence_3_score', 0),
            comp4_score=groq_result.get('competence_4_score', 0),
            comp5_score=groq_result.get('competence_5_score', 0),
            content=content
        )
        
        print(f"üì§ Sending to Gemini for refinement...")
        response = model.generate_content(prompt)
        text = response.text.strip()
        
        insights = extract_json_robust(text)
        print(f"‚úÖ Gemini refinement completed")
        return insights
        
    except Exception as e:
        print(f"‚ùå Gemini refinement error: {e}")
        # Return empty insights if fails
        return {f"competence_{i}_premium_insights": "" for i in range(1, 6)}


def combine_corrections(groq_result: dict, gemini_insights: dict) -> dict:
    """Combine Groq scores/feedback with Gemini premium insights"""
    combined = groq_result.copy()
    
    # Add premium insights to each competence feedback
    for i in range(1, 6):
        feedback_key = f"competence_{i}_feedback"
        insights_key = f"competence_{i}_premium_insights"
        
        if feedback_key in combined and insights_key in gemini_insights:
            insight = gemini_insights.get(insights_key, "")
            if insight:
                # Append premium insights
                combined[feedback_key] += f"\n\nüíé **Insights Premium:**\n{insight}"
    
    # Add general premium insights
    if "general_premium_insights" in gemini_insights:
        combined['general_comments'] += f"\n\nüíé **An√°lise Premium:**\n{gemini_insights['general_premium_insights']}"
    
    return combined


async def correct_essay_premium(title: str, theme: str, content: str, exam_type: str = 'enem', api_key_groq: str = '', api_key_gemini: str = '') -> dict:
    """
    Premium correction: Groq (initial) + Gemini (refinement)
    Now supports multiple exam types with specific criteria.
    """
    print(f"üåü === PREMIUM CORRECTION ({exam_type.upper()}) (Groq + Gemini) ===")
    
    # Import prompt_builder to use exam-specific prompts
    from .prompt_builder import create_correction_prompt
    
    # Get exam-specific prompt
    prompt = create_correction_prompt(exam_type, title, theme, content)
    print(f"‚úÖ Prompt espec√≠fico para {exam_type.upper()} criado")
    
    # Step 1: Groq initial correction with custom prompt
    print(f"Step 1/3: Groq initial correction for {exam_type.upper()}...")
    
    async def run_groq_70b():
        return await correct_with_groq_custom_prompt(
            title, theme, content, api_key_groq, prompt, model="llama-3.1-70b-versatile"
        )
        
    async def run_groq_8b():
        return await correct_with_groq_custom_prompt(
            title, theme, content, api_key_groq, prompt, model="llama-3.1-8b-instant"
        )
    
    try:
        # Premium uses the BEST model (70B) with retry
        groq_result = await retry_with_backoff(run_groq_70b, max_retries=2)
    except Exception as e:
        print(f"‚ö†Ô∏è Erro com modelo 70B: {e}. Tentando fallback para 8B...")
        logger.warning(f"Erro com modelo 70B: {e}. Tentando fallback para 8B...")
        # Fallback to 8B model if 70B fails
        groq_result = await retry_with_backoff(run_groq_8b, max_retries=2)
    
    # Step 2: Gemini refinement
    print("Step 2/3: Gemini refinement...")
    gemini_insights = await refine_with_gemini(title, theme, content, groq_result, api_key_gemini)
    
    # Step 3: Combine
    print("Step 3/3: Combining corrections...")
    final_result = combine_corrections(groq_result, gemini_insights)
    
    print(f"‚úÖ Premium correction completed. Score: {final_result.get('total_score')}")
    return final_result


async def correct_with_groq_custom_prompt(title: str, theme: str, content: str, api_key: str, custom_prompt: str, model: str = "llama-3.1-70b-versatile") -> dict:
    """Correct essay using Groq API with custom prompt (for exam-specific prompts)"""
    try:
        from groq import Groq
        
        client = Groq(api_key=api_key)
        
        print(f"üì§ Sending to Groq with custom prompt: {title}")
        logger.info(f"Sending to Groq: {title}")
        print(f"ü§ñ Model: {model}")
        
        # DEBUG PROMPT
        print(f"üìù PROMPT ENVIADO PARA GROQ:\n{custom_prompt[:500]}...")
        
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": custom_prompt}],
            temperature=0.2,
            max_tokens=2048
        )
        
        text = response.choices[0].message.content.strip()
        print(f"üì• RESPOSTA RAW GROQ:\n{text[:500]}...")
        
        data = extract_json_robust(text)
        data['strengths'] = json.dumps(data.get('strengths', []), ensure_ascii=False)
        data['improvements'] = json.dumps(data.get('improvements', []), ensure_ascii=False)
        
        print(f"‚úÖ Groq correction completed. Score: {data.get('total_score')}")
        logger.info(f"Groq correction completed. Score: {data.get('total_score')}")
        return data
        
    except Exception as e:
        print(f"‚ùå Groq error: {e}")
        logger.error(f"Groq error: {e}")
        raise


async def correct_with_gemini_custom_prompt(title: str, theme: str, content: str, api_key: str, custom_prompt: str) -> dict:
    """Correct essay using Gemini API with custom prompt (for exam-specific prompts)"""
    try:
        import google.generativeai as genai
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.0-flash')
        
        logger.info(f"Sending to Gemini: {title}")
        
        response = model.generate_content(
            custom_prompt,
            generation_config=genai.GenerationConfig(temperature=0.1, max_output_tokens=2048),
            safety_settings=[
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]
        )
        
        text = response.text.strip()
        data = extract_json_robust(text)
        data['strengths'] = json.dumps(data.get('strengths', []), ensure_ascii=False)
        data['improvements'] = json.dumps(data.get('improvements', []), ensure_ascii=False)
        
        logger.info(f"Gemini correction completed. Score: {data.get('total_score')}")
        return data
        
    except Exception as e:
        logger.error(f"Gemini error: {e}")
        raise
