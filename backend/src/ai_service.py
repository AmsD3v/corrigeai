"""
AI Service for Essay Correction - Multi-Provider Support
Supports: Groq, Gemini, HuggingFace, Together AI
"""

import json
import logging
import os
import asyncio
import re
from typing import Optional

logger = logging.getLogger(__name__)

def extract_json_robust(text: str) -> dict:
    """
    Extrai JSON de uma string de forma robusta, buscando o primeiro '{' e o √∫ltimo '}'.
    Remove blocos de c√≥digo markdown se houver.
    """
    text = text.strip()
    
    # Remove blocos de c√≥digo markdown ```json ... ```
    if "```" in text:
        # Tenta extrair conte√∫do dentro de ```json ou apenas ```
        match = re.search(r"```(?:json)?(.*?)```", text, re.DOTALL)
        if match:
            text = match.group(1).strip()
            
    # Encontra o primeiro '{' e o √∫ltimo '}'
    start = text.find('{')
    end = text.rfind('}')
    
    if start != -1 and end != -1:
        json_str = text[start:end+1]
        try:
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            logger.error(f"Erro ao decodificar JSON extra√≠do: {e}")
            # Tenta limpar v√≠rgulas finais (trailing commas) que o JSON padr√£o n√£o aceita
            try:
                json_str_clean = re.sub(r",\s*}", "}", json_str)
                json_str_clean = re.sub(r",\s*]", "]", json_str_clean)
                return json.loads(json_str_clean)
            except:
                pass
            raise ValueError(f"Falha ao extrair JSON v√°lido. Texto: {text[:100]}...")
    
    raise ValueError("Nenhum objeto JSON encontrado na resposta da IA")

async def retry_with_backoff(func, *args, max_retries=3, initial_delay=1, **kwargs):
    """
    Executa uma fun√ß√£o async com retry e backoff exponencial.
    """
    delay = initial_delay
    last_exception = None
    
    for attempt in range(max_retries):
        try:
            return await func(*args, **kwargs)
        except Exception as e:
            last_exception = e
            logger.warning(f"Tentativa {attempt+1}/{max_retries} falhou: {str(e)}. Retentando em {delay}s...")
            if attempt < max_retries - 1:
                await asyncio.sleep(delay)
                delay *= 2  # Backoff exponencial
    
    logger.error(f"Todas as {max_retries} tentativas falharam.")
    raise last_exception

# Provider configurations
AI_PROVIDERS = {
    'groq': {
        'name': 'Groq',
        'env_var': 'GROQ_API_KEY',
        'default_model': 'llama-3.3-70b-versatile'
    },
    'gemini': {
        'name': 'Google Gemini',
        'env_var': 'GEMINI_API_KEY',
        'default_model': 'gemini-2.0-flash'
    },
    'huggingface': {
        'name': 'HuggingFace',
        'env_var': 'HF_TOKEN',
        'default_model': 'mistralai/Mixtral-8x7B-Instruct-v0.1'
    },
    'together':  {
        'name': 'Together AI',
        'env_var': 'TOGETHER_API_KEY',
        'default_model': 'meta-llama/Llama-3-70b-chat-hf'
    }
}

# Prompt aprimorado com calibra√ß√£o e crit√©rios objetivos
CORRECTION_PROMPT = """Voc√™ √© um corretor OFICIAL do ENEM. Analise esta reda√ß√£o seguindo RIGOROSAMENTE os crit√©rios oficiais.

**üìä ESCALA DE CALIBRA√á√ÉO (distribui√ß√£o estat√≠stica t√≠pica):**
- 200 pontos: <5% das reda√ß√µes (texto excepcional, refer√™ncia nacional)
- 160 pontos: 15-20% (texto muito bom, acima da m√©dia)
- 120 pontos: 40-50% (texto adequado, dentro do esperado) ‚Üê FAIXA MAIS COMUM
- 80 pontos: 20-25% (texto mediano, abaixo do esperado)
- 40 pontos: 5-10% (texto insuficiente, problemas s√©rios)
- 0 pontos: <2% (texto inadequado, problemas grav√≠ssimos)

**üìù CHECKLIST OBRIGAT√ìRIO ANTES DE PONTUAR:**

Para CADA compet√™ncia, voc√™ DEVE verificar objetivamente:

**C1 - Norma Culta:**
‚ñ° Quantos erros de ortografia? ___
‚ñ° Quantos erros de pontua√ß√£o? ___
‚ñ° Quantos erros de concord√¢ncia? ___
‚ñ° Quantos erros de reg√™ncia? ___
‚Üí 0-2 erros = 160-200 | 3-5 erros = 120-160 | 6-10 erros = 80-120 | 11+ erros = 40-80

**C2 - Compreens√£o do Tema:**
‚ñ° O tema foi compreendido corretamente? (Sim/N√£o)
‚ñ° H√° tangenciamento? (N√£o/Leve/Moderado/Grave)
‚ñ° Desenvolvimento: (Superficial/Adequado/Aprofundado)
‚Üí Completo = 160-200 | Adequado = 120-160 | Tangente leve = 80-120

**C3 - Argumenta√ß√£o:**
‚ñ° Quantos argumentos bem desenvolvidos? ___
‚ñ° H√° repert√≥rio sociocultural? (N√£o/Superficial/Legitimado)
‚ñ° Argumenta√ß√£o √© autoral ou gen√©rica?
‚Üí 3+ argumentos + repert√≥rio legitimado = 160-200 | 2 argumentos adequados = 120-160 | 1-2 argumentos fracos = 80-120

**C4 - Coes√£o:**
‚ñ° Quantos conectivos ADEQUADOS usados? ___
‚ñ° H√° problemas de coer√™ncia? (N√£o/Leve/Grave)
‚ñ° Progress√£o textual: (Excelente/Boa/Adequada/Problem√°tica)
‚Üí 8+ conectivos variados = 160-200 | 5-7 conectivos = 120-160 | 3-4 conectivos = 80-120

**C5 - Proposta de Interven√ß√£o:**
‚ñ° A√á√ÉO detalhada? (Sim/N√£o)
‚ñ° AGENTE claro? (Sim/N√£o)
‚ñ° MODO/MEIO especificado? (Sim/N√£o)
‚ñ° EFEITO/FINALIDADE clara? (Sim/N√£o)
‚ñ° DETALHAMENTO suficiente? (Sim/N√£o)
‚Üí 5 elementos = 200 | 4 elementos = 160 | 3 elementos = 120 | 2 elementos = 80

**üéì EXEMPLOS DE CALIBRA√á√ÉO (few-shot learning):**

EXEMPLO 1 - Reda√ß√£o nota 840 (168 m√©dia):
"A tecnologia como ponte para a inclus√£o digital no Brasil"
- C1: 160pts (2 desvios leves de pontua√ß√£o)
- C2: 180pts (tema muito bem desenvolvido, perspectiva cr√≠tica)
- C3: 160pts (2 argumentos s√≥lidos, repert√≥rio de soci√≥logos)
- C4: 180pts (progress√£o clara, 9 conectivos variados)
- C5: 160pts (4 dos 5 elementos: a√ß√£o+agente+modo+efeito)
Caracter√≠sticas: linguagem fluida, repert√≥rio legitimado, estrutura clara, proposta vi√°vel.

EXEMPLO 2 - Reda√ß√£o nota 600 (120 m√©dia):
"Os desafios da mobilidade urbana nas grandes cidades"
- C1: 120pts (5 desvios: concord√¢ncia e acentua√ß√£o)
- C2: 120pts (tema adequadamente desenvolvido, sem aprofundamento)
- C3: 120pts (2 argumentos previs√≠veis, repert√≥rio superficial)
- C4: 120pts (5 conectivos, alguns repetidos)
- C5: 120pts (3 elementos: a√ß√£o+agente+modo)
Caracter√≠sticas: linguagem simples, argumentos gen√©ricos, estrutura b√°sica, proposta incompleta.

EXEMPLO 3 - Reda√ß√£o nota 400 (80 m√©dia):
"A importancia da educa√ßao finanseira"
- C1: 80pts (10 erros: ortografia, acentua√ß√£o, concord√¢ncia)
- C2: 80pts (tangenciamento moderado do tema)
- C3: 80pts (1 argumento desenvolvido, sem repert√≥rio)
- C4: 80pts (3 conectivos b√°sicos, repeti√ß√£o de ideias)
- C5: 80pts (2 elementos vagos: a√ß√£o+agente gen√©ricos)
Caracter√≠sticas: erros frequentes, pouco desenvolvimento, estrutura fr√°gil, proposta vaga.

**‚ö†Ô∏è DIRETRIZES CR√çTICAS:**
1. Seja OBJETIVO: conte erros, conectivos, argumentos
2. Seja CONSISTENTE: use a escala de calibra√ß√£o
3. Seja JUSTO: notas 120-160 s√£o NORMAIS, n√£o tenha medo de us√°-las
4. Seja CRITERIOSO: nota 200 exige perfei√ß√£o quase absoluta
5. EVITE: dar sempre a mesma nota ou notas muito extremas

**üìù REGRAS OBRIGAT√ìRIAS PARA FEEDBACKS:**

1. **strengths** DEVE conter EXATAMENTE 5 itens (um por compet√™ncia). MESMO que a reda√ß√£o seja fraca, encontre aspectos positivos relativos. NUNCA deixe vazio ou com menos de 5 itens.
   - Exemplo fraco: "C1: Apesar dos erros, o vocabul√°rio b√°sico √© adequado para a comunica√ß√£o"
   
2. **improvements** DEVE conter EXATAMENTE 5 itens (um por compet√™ncia), citando trechos espec√≠ficos do texto.
   - Exemplo: "C1: No trecho 'a desinforma√ß√£o √© um problema muito ruim', substituir por vocabul√°rio mais preciso"

3. **general_comments** DEVE ter no M√çNIMO 150 palavras em 3 par√°grafos: (1) an√°lise geral, (2) qualidades, (3) sugest√µes pr√°ticas.

4. PROIBIDO usar:
   - "Nenhum ponto forte identificado"
   - "N/A" ou "N/F"
   - Arrays vazios []
   - Frases gen√©ricas sem especificidade

Retorne APENAS JSON v√°lido:

```json
{{
  "competence_1_score": 120,
  "competence_1_feedback": "üìä An√°lise: Foram identificados X erros de ortografia e Y erros de pontua√ß√£o.\\n\\n‚úÖ Pontos Fortes: O vocabul√°rio b√°sico est√° adequado e h√° poucas repeti√ß√µes.\\n\\n‚ö†Ô∏è O que melhorar: Revisar a concord√¢ncia em 'os problema' e a pontua√ß√£o ap√≥s conectivos.",
  "competence_2_score": 120,
  "competence_2_feedback": "üìä An√°lise: O tema foi abordado de forma superficial.\\n\\n‚úÖ Pontos Fortes: H√° uma tentativa de contextualiza√ß√£o inicial.\\n\\n‚ö†Ô∏è O que melhorar: Desenvolver mais a rela√ß√£o causa-efeito do problema apresentado.",
  "competence_3_score": 80,
  "competence_3_feedback": "üìä An√°lise: Apresenta 1 argumento pouco desenvolvido.\\n\\n‚úÖ Pontos Fortes: H√° men√ß√£o a uma causa do problema.\\n\\n‚ö†Ô∏è O que melhorar: Adicionar dados estat√≠sticos ou cita√ß√µes de especialistas.",
  "competence_4_score": 80,
  "competence_4_feedback": "üìä An√°lise: Poucos conectivos identificados (3).\\n\\n‚úÖ Pontos Fortes: Uso correto de 'al√©m disso' para progress√£o.\\n\\n‚ö†Ô∏è O que melhorar: Diversificar conectivos, evitando repeti√ß√£o de 'portanto'.",
  "competence_5_score": 120,
  "competence_5_feedback": "üìä An√°lise: Proposta incompleta (2 de 5 elementos).\\n\\n‚úÖ Pontos Fortes: Menciona uma a√ß√£o governamental.\\n\\n‚ö†Ô∏è O que melhorar: Especificar o agente (quem far√°), o modo (como far√°) e o efeito esperado.",
  "total_score": 520,
  "strengths": [
    "C1: Apesar de alguns erros gramaticais, demonstra capacidade de escrita formal com vocabul√°rio adequado ao g√™nero dissertativo",
    "C2: Demonstra compreens√£o do tema central, mesmo que superficial, identificando corretamente a problem√°tica apresentada",
    "C3: Apresenta tentativa de argumenta√ß√£o com men√ß√£o a causas do problema, indicando potencial para desenvolvimento",
    "C4: Utiliza alguns conectivos adequadamente, mostrando no√ß√£o de progress√£o textual entre par√°grafos",
    "C5: Prop√µe uma solu√ß√£o, ainda que incompleta, demonstrando entendimento da necessidade de interven√ß√£o social"
  ],
  "improvements": [
    "C1: No trecho 'os problema da sociedade atual', corrigir para 'os problemas'. Revisar tamb√©m a pontua√ß√£o ap√≥s 'Portanto'",
    "C2: Aprofundar a discuss√£o sobre o tema, explicando COMO e POR QUE o problema afeta a sociedade brasileira",
    "C3: Adicionar pelo menos mais um argumento com repert√≥rio sociocultural (dados do IBGE, cita√ß√£o de fil√≥sofos, exemplos hist√≥ricos)",
    "C4: Substituir a terceira ocorr√™ncia de 'al√©m disso' por conectivos variados como 'outrossim', 'ademais' ou 'sob essa √≥tica'",
    "C5: Completar a proposta de interven√ß√£o especificando: QUEM executar√° (agente), COMO ser√° feito (modo), e QUAL o resultado esperado (efeito)"
  ],
  "general_comments": "Sua reda√ß√£o apresenta uma estrutura b√°sica de texto dissertativo-argumentativo, com introdu√ß√£o, desenvolvimento e conclus√£o. Voc√™ demonstra compreens√£o do tema proposto e consegue articular ideias de forma coerente, o que √© um bom ponto de partida.\\n\\nEntre os pontos positivos, destaca-se sua capacidade de manter o foco no tema e de propor uma solu√ß√£o para o problema. A escrita √© clara e voc√™ utiliza vocabul√°rio adequado ao g√™nero, ainda que com alguns deslizes gramaticais que podem ser facilmente corrigidos com revis√£o.\\n\\nPara melhorar sua nota, sugiro: (1) revisar o texto em voz alta para identificar erros de concord√¢ncia e pontua√ß√£o; (2) adicionar dados estat√≠sticos ou cita√ß√µes de pensadores para enriquecer a argumenta√ß√£o; e (3) detalhar sua proposta de interven√ß√£o com os 5 elementos exigidos - a√ß√£o, agente, modo, efeito e detalhamento. Continue praticando que voc√™ est√° no caminho certo para alcan√ßar notas mais altas!"
}}
```

**REDA√á√ÉO A AVALIAR:**

T√≠tulo: {title}
Tema: {theme}

{content}
"""


def get_active_provider() -> tuple[str, Optional[str]]:
    """
    Get active AI provider from database + environment.
    Returns: (provider_name, api_key)
    """
    from .database import SessionLocal, init_db_engine
    from .models import Settings
    
    print("\nüîç ==== CHECKING ACTIVE AI PROVIDER ====")
    
    # Ensure SessionLocal is initialized
    if SessionLocal is None:
        print("‚ö†Ô∏è SessionLocal not initialized, initializing now...")
        init_db_engine()
        # Re-import after initialization
        from .database import SessionLocal as SL
    else:
        SL = SessionLocal
    
    # Get correction provider and key from database
    db = SL()
    try:
        settings = db.query(Settings).first()
        if settings:
            active_provider = getattr(settings, 'correction_provider', None) or settings.active_ai_provider
            correction_api_key = getattr(settings, 'correction_api_key', None) or ''
            print(f"üìä Database correction_provider: {active_provider}")
            print(f"üîë Correction API key configured: {bool(correction_api_key)}")
        else:
            active_provider = "groq"
            correction_api_key = ''
            print(f"‚ö†Ô∏è No settings in DB, using default: {active_provider}")
    finally:
        db.close()
    
    # Usar chave do banco ou fallback para vari√°veis de ambiente
    if active_provider == "groq":
        api_key = correction_api_key or os.getenv('GROQ_API_KEY')
        if api_key:
            print(f"‚úÖ Using GROQ provider")
            logger.info("Using Groq AI provider")
            return ('groq', api_key)
        else:
            print("‚ùå Groq selected but no API key!")
            logger.error("Groq selected but no API key configured")
            return ('groq', None)
    
    elif active_provider == "gemini":
        api_key = correction_api_key or os.getenv('GEMINI_API_KEY')
        if api_key:
            print(f"‚úÖ Using GEMINI provider")
            logger.info("Using Gemini AI provider")
            return ('gemini', api_key)
        else:
            print("‚ùå Gemini selected but no API key!")
            logger.error("Gemini selected but no API key configured")
            return ('gemini', None)
    
    elif active_provider == "huggingface":
        api_key = correction_api_key or os.getenv('HF_TOKEN')
        if api_key:
            print(f"‚úÖ Using HuggingFace provider")
            return ('huggingface', api_key)
        else:
            print("‚ùå HuggingFace selected but no API key!")
            return ('huggingface', None)
    
    elif active_provider == "together":
        api_key = correction_api_key or os.getenv('TOGETHER_API_KEY')
        if api_key:
            print(f"‚úÖ Using Together AI provider")
            return ('together', api_key)
        else:
            print("‚ùå Together selected but no API key!")
            return ('together', None)
    
    elif active_provider == "cerebras":
        api_key = correction_api_key or os.getenv('CEREBRAS_API_KEY')
        if api_key:
            print(f"üß† Using Cerebras provider")
            return ('cerebras', api_key)
        else:
            print("‚ùå Cerebras selected but no API key!")
            return ('cerebras', None)
    
    # Unknown provider
    print(f"‚ùå Unknown provider in database: {active_provider}")
    logger.error(f"Unknown provider configured: {active_provider}")
    return (active_provider, None)


async def correct_with_groq(title: str, theme: str, content: str, api_key: str) -> dict:
    """Correct essay using Groq API"""
    try:
        from groq import Groq
        
        client = Groq(api_key=api_key)
        
        prompt = CORRECTION_PROMPT.format(title=title, theme=theme or "", content=content)
        
        print(f"üì§ Sending to Groq: {title}")
        logger.info(f"Sending to Groq: {title}")
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,  # Low temperature for consistent scoring
            max_tokens=4096
        )
        
        text = response.choices[0].message.content.strip()
        
        data = extract_json_robust(text)
        data['strengths'] = json.dumps(data.get('strengths', []), ensure_ascii=False)
        data['improvements'] = json.dumps(data.get('improvements', []), ensure_ascii=False)
        
        print(f"‚úÖ Groq correction completed. Score: {data.get('total_score')}")
        logger.info(f"Groq correction completed. Score: {data.get('total_score')}")
        return data
        
    except Exception as e:
        print(f"‚ùå Groq error: {e}")
        logger.error(f"Groq error: {e}")
        raise


async def correct_with_cerebras(title: str, theme: str, content: str, api_key: str) -> dict:
    """Correct essay using Cerebras API (OpenAI-compatible)"""
    try:
        from openai import OpenAI
        
        # Cerebras usa API compat√≠vel com OpenAI
        client = OpenAI(
            api_key=api_key,
            base_url="https://api.cerebras.ai/v1"
        )
        
        prompt = CORRECTION_PROMPT.format(title=title, theme=theme or "", content=content)
        
        print(f"üß† Sending to Cerebras: {title}")
        logger.info(f"Sending to Cerebras: {title}")
        
        response = client.chat.completions.create(
            model="llama-3.3-70b",  # Cerebras Llama 3.3 70B
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=2048
        )
        
        text = response.choices[0].message.content.strip()
        
        data = extract_json_robust(text)
        data['strengths'] = json.dumps(data.get('strengths', []), ensure_ascii=False)
        data['improvements'] = json.dumps(data.get('improvements', []), ensure_ascii=False)
        
        print(f"‚úÖ Cerebras correction completed. Score: {data.get('total_score')}")
        logger.info(f"Cerebras correction completed. Score: {data.get('total_score')}")
        return data
        
    except Exception as e:
        print(f"‚ùå Cerebras error: {e}")
        logger.error(f"Cerebras error: {e}")
        raise


async def correct_with_gemini(title: str, theme: str, content: str, api_key: str) -> dict:
    """Correct essay using Gemini API"""
    try:
        import google.generativeai as genai
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.0-flash')
        
        prompt = CORRECTION_PROMPT.format(title=title, theme=theme or "", content=content)
        
        logger.info(f"Sending to Gemini: {title}")
        
        response = model.generate_content(
            prompt,
            generation_config=genai.GenerationConfig(temperature=0.1, max_output_tokens=4096),
            safety_settings=[
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]
        )
        
        # Check for safety block
        if hasattr(response, 'candidates') and len(response.candidates) > 0:
            if response.candidates[0].finish_reason == 2:
                logger.warning("Gemini blocked by safety")
                raise Exception("Blocked by safety filters")
        
        text = response.text.strip()
        
        data = extract_json_robust(text)
        data['strengths'] = json.dumps(data.get('strengths', []), ensure_ascii=False)
        data['improvements'] = json.dumps(data.get('improvements', []), ensure_ascii=False)
        
        logger.info(f"Gemini correction completed. Score: {data.get('total_score')}")
        return data
        
    except Exception as e:
        logger.error(f"Gemini error: {e}")
        raise


async def correct_essay_with_gemini(title: str, theme: str, content: str, exam_type: str = 'enem') -> dict:
    """
    Main correction function - routes to active provider
    Maintains backward compatibility with existing code
    """
    provider, api_key = get_active_provider()
    
    if not api_key:
        raise Exception(f"API key not configured for provider: {provider}")
    
    print(f"ü§ñ Using AI provider: {AI_PROVIDERS[provider]['name']}")
    logger.info(f"Using AI provider: {AI_PROVIDERS[provider]['name']}")
    
    # Define wrapper functions for retry
    async def run_groq():
        # Import prompt_builder to use specific prompts
        from .prompt_builder import create_correction_prompt
        prompt = create_correction_prompt(exam_type, title, theme, content)
        return await correct_with_groq_custom_prompt(
            title, theme, content, api_key, prompt, model="llama-3.1-8b-instant"
        )
        
    async def run_gemini():
        # Import prompt_builder to use specific prompts
        from .prompt_builder import create_correction_prompt
        prompt = create_correction_prompt(exam_type, title, theme, content)
        return await correct_with_gemini_custom_prompt(title, theme, content, api_key, prompt)

    try:
        if provider == 'groq':
            return await retry_with_backoff(run_groq, max_retries=3)
        elif provider == 'gemini':
           return await retry_with_backoff(run_gemini, max_retries=3)
        elif provider == 'cerebras':
            async def run_cerebras():
                from .prompt_builder import create_correction_prompt
                prompt = create_correction_prompt(exam_type, title, theme, content)
                return await correct_with_cerebras_custom_prompt(title, theme, content, api_key, prompt)
            return await retry_with_backoff(run_cerebras, max_retries=3)
        elif provider == 'huggingface':
            # TODO: Implement HuggingFace
            raise Exception("HuggingFace provider not implemented yet")
        elif provider == 'together':
            # TODO: Implement Together AI
            raise Exception("Together AI provider not implemented yet")
        else:
            raise Exception(f"Unknown provider: {provider}")
            
    except Exception as e:
        # Log error and re-raise (no silent fallback)
        print(f"‚ùå AI correction failed: {e}")
        logger.error(f"AI correction failed: {e}")
        raise Exception(f"Falha na corre√ß√£o com {provider}: {str(e)}. Verifique se a API key est√° configurada corretamente.")


async def generate_theme_with_gemini(category: str) -> str:
    """Generate theme using active provider"""
    provider, api_key = get_active_provider()
    
    if provider == 'groq' and api_key:
        try:
            from groq import Groq
            client = Groq(api_key=api_key)
            response = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": f"Gere um tema dissertativo sobre {category}. M√°ximo 15 palavras. Responda APENAS o tema, sem aspas."}],
                temperature=0.8,
                max_tokens=100
            )
            return response.choices[0].message.content.strip().replace('"', '').replace("'", "")
        except:
            pass
    
    # Fallback themes
    return {
        'geral': 'A import√¢ncia da educa√ß√£o no Brasil contempor√¢neo',
        'educacao': 'Desafios da forma√ß√£o de professores no Brasil',
        'tecnologia': 'O impacto da intelig√™ncia artificial na sociedade',
        'meio_ambiente': 'Sustentabilidade e desenvolvimento econ√¥mico',
        'sociedade': 'A import√¢ncia do di√°logo na resolu√ß√£o de conflitos',
        'saude': 'Desafios do sistema de sa√∫de p√∫blica no Brasil'
    }.get(category, 'A educa√ß√£o como instrumento de transforma√ß√£o social')

# ===== PREMIUM CORRECTION FUNCTIONS =====

def create_refinement_prompt(exam_type: str, groq_result: dict, content: str) -> str:
    """
    Cria prompt de refinement din√¢mico baseado em exam_criteria.py.
    Isso garante que Premium funcione corretamente para todos os vestibulares.
    """
    from .exam_criteria import get_exam_criteria
    criteria = get_exam_criteria(exam_type)
    
    # Formata compet√™ncias com pesos corretos do vestibular
    comp_scores = []
    for i, comp in enumerate(criteria.competencies, 1):
        score = groq_result.get(f'competence_{i}_score', 0)
        max_score = int(criteria.weights[i-1])
        comp_scores.append(f"Compet√™ncia {i} ({comp}): {score}/{max_score}")
    
    # Gera campos JSON dinamicamente baseado no n√∫mero de compet√™ncias
    num_comps = len(criteria.competencies)
    json_fields = ",\n  ".join([f'"competence_{i}_premium_insights": "..."' for i in range(1, num_comps+1)])
    
    return f"""Voc√™ √© um ESPECIALISTA PREMIUM em reda√ß√£o {criteria.short_name}.

Recebeu esta corre√ß√£o inicial para o vestibular {criteria.short_name} (nota m√°xima: {criteria.max_score}):

**NOTAS:**
{chr(10).join(comp_scores)}

Para CADA compet√™ncia avaliada, adicione insights premium espec√≠ficos para {criteria.short_name} com:
1. Exemplos pr√°ticos extra√≠dos do texto
2. Como reda√ß√µes excelentes deste vestibular fazem
3. Sugest√£o estrat√©gica avan√ßada

Retorne JSON:
{{
  {json_fields},
  "general_premium_insights": "Vis√£o estrat√©gica geral para {criteria.short_name}"
}}

Texto:
{content}
"""


async def refine_with_gemini(title: str, theme: str, content: str, groq_result: dict, api_key: str, exam_type: str = 'enem') -> dict:
    """Refine Groq correction with Gemini premium insights - suporta multi-vestibular"""
    try:
        import google.generativeai as genai
        from .exam_criteria import get_exam_criteria
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.0-flash')
        
        # Usar prompt din√¢mico baseado em exam_type
        prompt = create_refinement_prompt(exam_type, groq_result, content)
        
        print(f"üì§ Sending to Gemini for refinement ({exam_type.upper()})...")
        response = model.generate_content(prompt)
        text = response.text.strip()
        
        insights = extract_json_robust(text)
        print(f"‚úÖ Gemini refinement completed for {exam_type.upper()}")
        return insights
        
    except Exception as e:
        print(f"‚ùå Gemini refinement error: {e}")
        # Retorna insights vazios para o n√∫mero de compet√™ncias do vestibular
        try:
            from .exam_criteria import get_exam_criteria
            criteria = get_exam_criteria(exam_type)
            return {f"competence_{i}_premium_insights": "" for i in range(1, len(criteria.competencies)+1)}
        except:
            return {f"competence_{i}_premium_insights": "" for i in range(1, 6)}


def combine_corrections(groq_result: dict, gemini_insights: dict) -> dict:
    """Combine Groq scores/feedback with Gemini premium insights"""
    combined = groq_result.copy()
    
    # Add premium insights to each competence feedback
    for i in range(1, 6):
        feedback_key = f"competence_{i}_feedback"
        insights_key = f"competence_{i}_premium_insights"
        
        if feedback_key in combined and insights_key in gemini_insights:
            insight = gemini_insights.get(insights_key, "")
            if insight:
                # Append premium insights
                combined[feedback_key] += f"\n\nüíé **Insights Premium:**\n{insight}"
    
    # Add general premium insights
    if "general_premium_insights" in gemini_insights:
        combined['general_comments'] += f"\n\nüíé **An√°lise Premium:**\n{gemini_insights['general_premium_insights']}"
    
    return combined


async def correct_essay_premium(title: str, theme: str, content: str, exam_type: str = 'enem', api_key_groq: str = '', api_key_gemini: str = '') -> dict:
    """
    Premium correction: Dupla corre√ß√£o paralela (Groq + Gemini) + √Årbitro
    
    Fluxo:
    1. Groq 70B e Gemini corrigem em paralelo
    2. Compara notas - se diferen√ßa > 40pts em qualquer compet√™ncia:
       ‚Üí √Årbitro (Groq 8B) decide
    3. Sen√£o: m√©dia ponderada (Groq 60%, Gemini 40%)
    """
    import asyncio
    
    print(f"üåü === PREMIUM CORRECTION V2 ({exam_type.upper()}) - DUPLA CORRE√á√ÉO + √ÅRBITRO ===")
    
    # Import prompt_builder para prompts espec√≠ficos por vestibular
    from .prompt_builder import create_correction_prompt
    
    # Cria prompt espec√≠fico para o vestibular
    prompt = create_correction_prompt(exam_type, title, theme, content)
    print(f"‚úÖ Prompt espec√≠fico para {exam_type.upper()} criado")
    
    # ===== STEP 1: CORRE√á√ÉO PARALELA =====
    print(f"Step 1/3: Corre√ß√£o paralela (Groq 70B + Gemini)...")
    
    async def run_groq():
        try:
            return await retry_with_backoff(
                lambda: correct_with_groq_custom_prompt(
                    title, theme, content, api_key_groq, prompt, model="llama-3.3-70b-versatile"
                ),
                max_retries=2
            )
        except Exception as e:
            print(f"‚ö†Ô∏è Groq 70B falhou: {e}. Tentando 8B...")
            return await correct_with_groq_custom_prompt(
                title, theme, content, api_key_groq, prompt, model="llama-3.1-8b-instant"
            )
    
    async def run_gemini():
        try:
            return await correct_with_gemini_custom_prompt(
                title, theme, content, api_key_gemini, prompt
            )
        except Exception as e:
            print(f"‚ö†Ô∏è Gemini falhou: {e}")
            return None
    
    # Executa em paralelo
    results = await asyncio.gather(run_groq(), run_gemini(), return_exceptions=True)
    
    groq_result = results[0] if not isinstance(results[0], Exception) else None
    gemini_result = results[1] if not isinstance(results[1], Exception) else None
    
    # Tratamento de erros
    if groq_result is None and gemini_result is None:
        raise Exception("Ambas IAs falharam na corre√ß√£o")
    
    if groq_result is None:
        print("‚ö†Ô∏è Apenas Gemini retornou. Usando resultado √∫nico.")
        return gemini_result
    
    if gemini_result is None:
        print("‚ö†Ô∏è Apenas Groq retornou. Usando resultado √∫nico com insights antigos.")
        gemini_insights = await refine_with_gemini(title, theme, content, groq_result, api_key_gemini, exam_type)
        return combine_corrections(groq_result, gemini_insights)
    
    print(f"‚úÖ Groq Score: {groq_result.get('total_score')} | Gemini Score: {gemini_result.get('total_score')}")
    
    # ===== STEP 2: VERIFICAR DIVERG√äNCIA =====
    print(f"Step 2/3: Verificando diverg√™ncias...")
    needs_arb, divergent_comps = check_needs_arbitration(groq_result, gemini_result, threshold=40)
    
    # ===== STEP 3: √ÅRBITRO OU M√âDIA =====
    if needs_arb:
        print(f"Step 3/3: Chamando √°rbitro para {len(divergent_comps)} compet√™ncia(s)...")
        final_result = await arbitrate_scores(
            groq_result, gemini_result, divergent_comps, 
            content, api_key_groq, exam_type
        )
    else:
        print(f"Step 3/3: Calculando m√©dia ponderada...")
        final_result = average_scores(groq_result, gemini_result)
    
    print(f"‚úÖ Premium V2 completed. Score: {final_result.get('total_score')}")
    return final_result


async def correct_with_groq_custom_prompt(title: str, theme: str, content: str, api_key: str, custom_prompt: str, model: str = "llama-3.3-70b-versatile") -> dict:
    """Correct essay using Groq API with custom prompt (for exam-specific prompts)"""
    try:
        from groq import Groq
        
        client = Groq(api_key=api_key)
        
        print(f"üì§ Sending to Groq with custom prompt: {title}")
        logger.info(f"Sending to Groq: {title}")
        print(f"ü§ñ Model: {model}")
        
        # DEBUG PROMPT
        print(f"üìù PROMPT ENVIADO PARA GROQ:\n{custom_prompt[:500]}...")
        
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": custom_prompt}],
            temperature=0.2,
            max_tokens=2048
        )
        
        text = response.choices[0].message.content.strip()
        print(f"üì• RESPOSTA RAW GROQ:\n{text[:500]}...")
        
        data = extract_json_robust(text)
        data['strengths'] = json.dumps(data.get('strengths', []), ensure_ascii=False)
        data['improvements'] = json.dumps(data.get('improvements', []), ensure_ascii=False)
        
        print(f"‚úÖ Groq correction completed. Score: {data.get('total_score')}")
        logger.info(f"Groq correction completed. Score: {data.get('total_score')}")
        return data
        
    except Exception as e:
        print(f"‚ùå Groq error: {e}")
        logger.error(f"Groq error: {e}")
        raise


async def correct_with_gemini_custom_prompt(title: str, theme: str, content: str, api_key: str, custom_prompt: str) -> dict:
    """Correct essay using Gemini API with custom prompt (for exam-specific prompts)"""
    try:
        import google.generativeai as genai
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.0-flash')
        
        logger.info(f"Sending to Gemini: {title}")
        
        response = model.generate_content(
            custom_prompt,
            generation_config=genai.GenerationConfig(temperature=0.1, max_output_tokens=2048),
            safety_settings=[
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]
        )
        
        text = response.text.strip()
        data = extract_json_robust(text)
        data['strengths'] = json.dumps(data.get('strengths', []), ensure_ascii=False)
        data['improvements'] = json.dumps(data.get('improvements', []), ensure_ascii=False)
        
        logger.info(f"Gemini correction completed. Score: {data.get('total_score')}")
        return data
        
    except Exception as e:
        logger.error(f"Gemini error: {e}")
        raise


async def correct_with_cerebras_custom_prompt(title: str, theme: str, content: str, api_key: str, custom_prompt: str) -> dict:
    """Correct essay using Cerebras API with custom prompt (for exam-specific prompts)"""
    try:
        from openai import OpenAI
        
        # Cerebras usa API compat√≠vel com OpenAI
        client = OpenAI(
            api_key=api_key,
            base_url="https://api.cerebras.ai/v1"
        )
        
        print(f"üß† Sending to Cerebras: {title}")
        logger.info(f"Sending to Cerebras: {title}")
        
        response = client.chat.completions.create(
            model="llama-3.3-70b",
            messages=[{"role": "user", "content": custom_prompt}],
            temperature=0.2,
            max_tokens=2048
        )
        
        text = response.choices[0].message.content.strip()
        data = extract_json_robust(text)
        data['strengths'] = json.dumps(data.get('strengths', []), ensure_ascii=False)
        data['improvements'] = json.dumps(data.get('improvements', []), ensure_ascii=False)
        
        print(f"‚úÖ Cerebras correction completed. Score: {data.get('total_score')}")
        logger.info(f"Cerebras correction completed. Score: {data.get('total_score')}")
        return data
        
    except Exception as e:
        print(f"‚ùå Cerebras error: {e}")
        logger.error(f"Cerebras error: {e}")
        raise


# ===== DUAL CORRECTION + ARBITRATOR FUNCTIONS =====

def average_scores(groq_result: dict, gemini_result: dict, groq_weight: float = 0.6) -> dict:
    """
    Calcula m√©dia ponderada das notas de Groq e Gemini.
    Combina feedbacks de ambas IAs.
    Default: Groq 60%, Gemini 40%
    """
    gemini_weight = 1.0 - groq_weight
    combined = {}
    
    # M√©dia ponderada das notas
    for i in range(1, 6):
        score_key = f"competence_{i}_score"
        groq_score = groq_result.get(score_key, 0) or 0
        gemini_score = gemini_result.get(score_key, 0) or 0
        
        # M√©dia ponderada arredondada para m√∫ltiplo de 20 (escala ENEM)
        avg = groq_score * groq_weight + gemini_score * gemini_weight
        combined[score_key] = int(round(avg / 20) * 20)  # Arredonda para 0, 20, 40, 60...
        
        # Combina feedbacks
        feedback_key = f"competence_{i}_feedback"
        groq_fb = groq_result.get(feedback_key, "")
        gemini_fb = gemini_result.get(feedback_key, "")
        combined[feedback_key] = f"{groq_fb}\n\nüíé **Segunda An√°lise:**\n{gemini_fb}" if gemini_fb else groq_fb
    
    # Total
    combined['total_score'] = sum(combined.get(f"competence_{i}_score", 0) for i in range(1, 6))
    
    # Outros campos
    combined['strengths'] = groq_result.get('strengths', '[]')
    combined['improvements'] = groq_result.get('improvements', '[]')
    combined['general_comments'] = f"{groq_result.get('general_comments', '')}\n\nüíé **An√°lise Complementar:**\n{gemini_result.get('general_comments', '')}"
    
    print(f"üìä M√©dia ponderada calculada. Total: {combined['total_score']}")
    return combined


def check_needs_arbitration(groq_result: dict, gemini_result: dict, threshold: int = 40) -> tuple[bool, list]:
    """
    Verifica se h√° discrep√¢ncia significativa entre as corre√ß√µes.
    Retorna (precisa_arbitragem, lista_competencias_divergentes)
    """
    divergent_comps = []
    
    for i in range(1, 6):
        score_key = f"competence_{i}_score"
        groq_score = groq_result.get(score_key, 0) or 0
        gemini_score = gemini_result.get(score_key, 0) or 0
        diff = abs(groq_score - gemini_score)
        
        if diff > threshold:
            divergent_comps.append({
                'competence': i,
                'groq_score': groq_score,
                'gemini_score': gemini_score,
                'difference': diff
            })
            print(f"‚ö†Ô∏è Diverg√™ncia C{i}: Groq={groq_score} vs Gemini={gemini_score} (diff={diff})")
    
    needs_arb = len(divergent_comps) > 0
    if needs_arb:
        print(f"üîî ARBITRAGEM NECESS√ÅRIA para {len(divergent_comps)} compet√™ncia(s)")
    else:
        print(f"‚úÖ Notas concordantes (threshold={threshold})")
    
    return needs_arb, divergent_comps


def create_arbitration_prompt(groq_result: dict, gemini_result: dict, divergent_comps: list, content: str, exam_type: str) -> str:
    """Cria prompt para o √°rbitro decidir entre notas discrepantes"""
    from .exam_criteria import get_exam_criteria
    criteria = get_exam_criteria(exam_type)
    
    divergence_text = ""
    for div in divergent_comps:
        i = div['competence']
        comp_name = criteria.competencies[i-1] if i <= len(criteria.competencies) else f"Compet√™ncia {i}"
        divergence_text += f"""
**Compet√™ncia {i} ({comp_name}):**
- IA 1 (Groq): {div['groq_score']}/200
- IA 2 (Gemini): {div['gemini_score']}/200
- Diferen√ßa: {div['difference']} pontos
"""
    
    return f"""Voc√™ √© um √ÅRBITRO ESPECIALISTA em corre√ß√£o de reda√ß√µes {criteria.short_name}.

Duas IAs corrigiram a mesma reda√ß√£o e discordam significativamente em algumas compet√™ncias:
{divergence_text}

Analise a reda√ß√£o abaixo e DECIDA a nota correta para cada compet√™ncia divergente.
Use a escala oficial: 0, 40, 80, 120, 160 ou 200.

IMPORTANTE: Sua decis√£o deve ser baseada nos crit√©rios oficiais do {criteria.short_name}.
Seja preciso e justo.

Retorne APENAS JSON no formato:
{{
  "arbitrated_scores": {{
    "competence_1_score": <sua decis√£o ou null se n√£o divergiu>,
    "competence_2_score": <sua decis√£o ou null se n√£o divergiu>,
    "competence_3_score": <sua decis√£o ou null se n√£o divergiu>,
    "competence_4_score": <sua decis√£o ou null se n√£o divergiu>,
    "competence_5_score": <sua decis√£o ou null se n√£o divergiu>
  }},
  "justification": "Breve justificativa para as decis√µes"
}}

REDA√á√ÉO:
{content}
"""


async def arbitrate_scores(groq_result: dict, gemini_result: dict, divergent_comps: list, 
                           content: str, api_key: str, exam_type: str) -> dict:
    """
    Usa uma terceira IA (Groq 8B - mais r√°pido) para decidir entre notas divergentes.
    Retorna resultado final combinado.
    """
    print(f"‚öñÔ∏è Iniciando arbitragem para {len(divergent_comps)} compet√™ncias...")
    
    try:
        from groq import Groq
        
        prompt = create_arbitration_prompt(groq_result, gemini_result, divergent_comps, content, exam_type)
        
        client = Groq(api_key=api_key)
        response = client.chat.completions.create(
            model="llama-3.1-8b-instant",  # Modelo r√°pido para arbitragem
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            max_tokens=1024
        )
        
        text = response.choices[0].message.content.strip()
        arb_data = extract_json_robust(text)
        arbitrated = arb_data.get('arbitrated_scores', {})
        justification = arb_data.get('justification', '')
        
        print(f"‚öñÔ∏è √Årbitro decidiu: {arbitrated}")
        print(f"üìù Justificativa: {justification[:100]}...")
        
        # Monta resultado final
        combined = groq_result.copy()
        
        for i in range(1, 6):
            score_key = f"competence_{i}_score"
            arb_score = arbitrated.get(score_key)
            
            if arb_score is not None:
                # Usa nota do √°rbitro
                combined[score_key] = int(arb_score)
                combined[f"competence_{i}_feedback"] += f"\n\n‚öñÔ∏è **Nota Arbitrada:** Esta compet√™ncia teve diverg√™ncia entre corretores e foi reavaliada."
            else:
                # Usa m√©dia das IAs para compet√™ncias n√£o divergentes
                groq_score = groq_result.get(score_key, 0) or 0
                gemini_score = gemini_result.get(score_key, 0) or 0
                combined[score_key] = int(round((groq_score * 0.6 + gemini_score * 0.4) / 20) * 20)
        
        # Recalcula total
        combined['total_score'] = sum(combined.get(f"competence_{i}_score", 0) for i in range(1, 6))
        
        # Adiciona justificativa ao coment√°rio geral
        combined['general_comments'] += f"\n\n‚öñÔ∏è **Nota de Arbitragem:**\n{justification}"
        
        print(f"‚úÖ Arbitragem conclu√≠da. Total: {combined['total_score']}")
        return combined
        
    except Exception as e:
        print(f"‚ùå Erro na arbitragem: {e}. Usando m√©dia simples como fallback.")
        logger.error(f"Arbitration error: {e}")
        return average_scores(groq_result, gemini_result)

